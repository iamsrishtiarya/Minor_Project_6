{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551adf10",
   "metadata": {},
   "source": [
    "### Step 1: Define the Custom Dataset Class `ChestXrayDataset`\n",
    "\n",
    "This section defines a custom PyTorch `Dataset` class to load chest X-ray images from the DA and DB datasets. The dataset includes images in two formats: `.jpg` and `.dcm` (DICOM format). \n",
    "\n",
    "Key steps in the `ChestXrayDataset` class:\n",
    "- **Data Source**: Images are loaded from two folders: `images/da` and `images/db`.\n",
    "- **Label Extraction**: \n",
    "  - Images starting with `n` are labeled **0** (TB Negative).\n",
    "  - Images starting with `p` are labeled **1** (TB Positive).\n",
    "- **DICOM Handling**: \n",
    "  - DICOM images are normalized to the 0-255 range and converted into 8-bit RGB format.\n",
    "- **Transformations**: \n",
    "  - Images are optionally resized and normalized during loading if a transform is provided.\n",
    "\n",
    "This dataset class prepares the data for further processing in the model training and evaluation pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c06be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 19.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 13.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pydicom\n",
      "Successfully installed pydicom-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8b1989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp313-cp313-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.5)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
      "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.6/110.9 MB 16.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 7.3/110.9 MB 21.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 13.1/110.9 MB 23.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 19.4/110.9 MB 24.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 26.0/110.9 MB 25.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 32.0/110.9 MB 26.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 38.3/110.9 MB 27.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 44.0/110.9 MB 27.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 49.3/110.9 MB 26.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 55.3/110.9 MB 27.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 60.0/110.9 MB 26.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 64.5/110.9 MB 26.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 70.8/110.9 MB 26.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 77.6/110.9 MB 27.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 82.8/110.9 MB 26.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 89.7/110.9 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 95.4/110.9 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 100.9/110.9 MB 27.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 107.0/110.9 MB 27.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 27.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/110.9 MB 27.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 110.9/110.9 MB 25.4 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.24.1-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.9.1-cp313-cp313-win_amd64.whl (665 kB)\n",
      "   ---------------------------------------- 0.0/665.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 665.3/665.3 kB 26.8 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 28.2 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 5.8/6.3 MB 27.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 25.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 18.7 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.20.1 fsspec-2025.12.0 mpmath-1.3.0 networkx-3.6.1 sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78d65b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kagglehub) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\aryas\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, kagglehub\n",
      "Successfully installed kagglehub-0.3.13 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c44f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/yasserhessein/tuberculosis-chest-x-rays-images?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.3M/26.3M [00:04<00:00, 6.04MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\aryas\\.cache\\kagglehub\\datasets\\yasserhessein\\tuberculosis-chest-x-rays-images\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\n",
    "    \"yasserhessein/tuberculosis-chest-x-rays-images\"\n",
    ")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f78fb698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dataset of Tuberculosis Chest X-rays Images']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b59939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal Chest X-rays', 'TB Chest X-rays']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.path.join(path, \"Dataset of Tuberculosis Chest X-rays Images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#Define ChestXrayDataset\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        base_path = os.path.join(\n",
    "            root_dir,\n",
    "            \"Dataset of Tuberculosis Chest X-rays Images\"\n",
    "        )\n",
    "\n",
    "        normal_path = os.path.join(base_path, \"Normal Chest X-rays\")\n",
    "        tb_path = os.path.join(base_path, \"TB Chest X-rays\")\n",
    "\n",
    "        # Normal images → label 0\n",
    "        for file in os.listdir(normal_path):\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.dcm')):\n",
    "                self.samples.append(\n",
    "                    (os.path.join(normal_path, file), 0)\n",
    "                )\n",
    "\n",
    "        # TB images → label 1\n",
    "        for file in os.listdir(tb_path):\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.dcm')):\n",
    "                self.samples.append(\n",
    "                    (os.path.join(tb_path, file), 1)\n",
    "                )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "\n",
    "        if img_path.endswith(\".dcm\"):\n",
    "            dicom = pydicom.dcmread(img_path)\n",
    "            image = dicom.pixel_array\n",
    "            image = Image.fromarray(image).convert(\"RGB\")\n",
    "        else:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804e7432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 3008\n"
     ]
    }
   ],
   "source": [
    "dataset = ChestXrayDataset(\n",
    "    root_dir=path,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(\"Total images:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf68d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 2. Define ChestXrayDataset\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        da_path = os.path.join(root_dir, 'images', 'da')\n",
    "        db_path = os.path.join(root_dir, 'images', 'db')\n",
    "\n",
    "        # Gather all image paths from both DA and DB folders\n",
    "        for folder in [da_path, db_path]:\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.endswith('.jpg') or filename.endswith('.dcm'):\n",
    "                    full_path = os.path.join(folder, filename)\n",
    "                    self.image_paths.append(full_path)\n",
    "\n",
    "                    # Extract true filename without train_/test_/da_/db_ prefix\n",
    "                    parts = filename.split('_')\n",
    "                    true_filename = parts[-1]  # Always take last part\n",
    "\n",
    "                    if true_filename.startswith('n') or 'n' in true_filename[:2]:\n",
    "                        self.labels.append(0)  # TB Negative\n",
    "                    elif true_filename.startswith('p') or 'p' in true_filename[:2]:\n",
    "                        self.labels.append(1)  # TB Positive\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected filename format: {filename}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "    \n",
    "        if img_path.endswith('.jpg'):\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "        elif img_path.endswith('.dcm'):\n",
    "            dicom = pydicom.dcmread(img_path)\n",
    "            img_array = dicom.pixel_array\n",
    "    \n",
    "            # Normalize and convert to uint8\n",
    "            img_array = img_array.astype(np.float32)  # Convert to float\n",
    "            img_array = (img_array - np.min(img_array)) / (np.max(img_array) - np.min(img_array))  # Normalize to [0,1]\n",
    "            img_array = (img_array * 255).astype(np.uint8)  # Scale to [0,255] and convert to uint8\n",
    "    \n",
    "            img_array = np.stack((img_array,)*3, axis=-1)  # Make it 3-channel (RGB)\n",
    "            image = Image.fromarray(img_array)\n",
    "    \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {img_path}\")\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0133ca",
   "metadata": {},
   "source": [
    "### Step 2: Define Image Transformations\n",
    "\n",
    "Before feeding images into the model, basic preprocessing transformations are applied:\n",
    "\n",
    "- **Resize**: Images are resized to `224x224` pixels to match the expected input size for ResNet18.\n",
    "- **ToTensor**: Images are converted from PIL format into PyTorch tensors.\n",
    "- **Normalize**: Pixel values are normalized with a mean of `0.5` and a standard deviation of `0.5`. \n",
    "  - This scales pixel intensities from [0,1] to approximately [-1,1], which helps improve model training stability.\n",
    "\n",
    "These transformations ensure consistency across the dataset and help the model generalize better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813f117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch Tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to mean=0.5, std=0.5\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750de323",
   "metadata": {},
   "source": [
    "### Step 3: Create Dataset Instances and DataLoaders\n",
    "\n",
    "After defining the dataset and transformations, the dataset is prepared for training and validation:\n",
    "\n",
    "- **Dataset Instance**: \n",
    "  - `ChestXrayDataset` is instantiated using the root directory and the defined transformations.\n",
    "- **Train-Validation Split**:\n",
    "  - The dataset is split into **80% training** and **20% validation** subsets using `random_split`.\n",
    "- **DataLoaders**:\n",
    "  - `train_loader` and `val_loader` are created to efficiently load batches of images during training and validation.\n",
    "  - Training DataLoader uses `shuffle=True` to ensure random batches during training.\n",
    "  - Validation DataLoader uses `shuffle=False` for consistent evaluation.\n",
    "\n",
    "DataLoaders enable efficient mini-batch training and evaluation on the GPU or CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79fc1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e210f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 2406\n",
      "Validation images: 602\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=16, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Validation images: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3777958",
   "metadata": {},
   "source": [
    "### Step 4: Define and Customize the Deep Learning Model (ResNet18)\n",
    "\n",
    "In this step, a deep learning model is prepared for TB classification:\n",
    "\n",
    "- **Pretrained Model**: \n",
    "  - ResNet18 pretrained on ImageNet is loaded using `ResNet18_Weights.DEFAULT`.\n",
    "- **Freezing Layers**:\n",
    "  - Early layers of the network are frozen to retain previously learned features and speed up training.\n",
    "- **Custom Fully Connected Layer**:\n",
    "  - The original fully connected (fc) layer is replaced with:\n",
    "    - A `Linear` layer reducing features to 128 dimensions.\n",
    "    - A `ReLU` activation.\n",
    "    - A `Dropout` layer (to prevent overfitting).\n",
    "    - A final `Linear` layer with 1 neuron followed by a `Sigmoid` activation for binary classification (TB Positive or Negative).\n",
    "- **Device Assignment**:\n",
    "  - The model is moved to GPU if available, otherwise it uses CPU.\n",
    "\n",
    "This setup enables efficient fine-tuning of a strong feature extractor (ResNet18) specifically for the TB classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56d4abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\aryas/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained ResNet18\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "# Freeze early layers (optional for faster training)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected (fc) layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(128, 1),  # 1 output neuron (binary classification)\n",
    "    nn.Sigmoid()        # To output probability between 0 and 1\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71bb48",
   "metadata": {},
   "source": [
    "### Step 5: Define the Training Loop\n",
    "\n",
    "This section defines the `train_model` function, which handles the complete training and validation process:\n",
    "\n",
    "- **Timing**:\n",
    "  - The training duration is recorded for reporting.\n",
    "- **Model States**:\n",
    "  - The model alternates between `train()` and `eval()` modes depending on the phase (training or validation).\n",
    "- **Loss Tracking**:\n",
    "  - Training and validation losses are computed and stored for each epoch.\n",
    "- **Gradient Updates**:\n",
    "  - During the training phase, gradients are computed and the optimizer updates model weights.\n",
    "- **Best Model Tracking**:\n",
    "  - The model's weights achieving the lowest validation loss are saved during training.\n",
    "- **Learning Rate Scheduler**:\n",
    "  - The learning rate is adjusted periodically to help improve convergence.\n",
    "- **Return Values**:\n",
    "  - The function returns the best-performing model and lists of training and validation losses for further analysis.\n",
    "\n",
    "This structure ensures the model is properly trained, monitored, and optimized over the specified number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe355372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=15):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                loader = train_loader\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                loader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float().unsqueeze(1)  # Make sure labels are float and have shape [batch_size,1]\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(loader.dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "\n",
    "                # Deep copy the model if it has better val loss\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        scheduler.step()\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Loss: {best_loss:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ba8e2",
   "metadata": {},
   "source": [
    "### Step 6: Configure the Training Parameters and Start Training\n",
    "\n",
    "This step sets up the key components required for training the model:\n",
    "\n",
    "- **Loss Function**:\n",
    "  - `BCELoss` (Binary Cross-Entropy Loss) is used because this is a binary classification task (TB Positive vs. TB Negative).\n",
    "- **Optimizer**:\n",
    "  - `Adam` optimizer is used to update model weights, focusing only on the new classifier layers (`model.fc.parameters()`).\n",
    "- **Learning Rate Scheduler**:\n",
    "  - A `StepLR` scheduler reduces the learning rate by a factor of 0.1 every 5 epochs, helping to refine training and avoid overshooting minima.\n",
    "- **Number of Epochs**:\n",
    "  - The model is trained for 15 epochs.\n",
    "- **Training Execution**:\n",
    "  - The `train_model` function is called to initiate the training process using the defined criterion, optimizer, and scheduler.\n",
    "\n",
    "This setup ensures efficient training, faster convergence, and better generalization of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94753ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "------------------------------\n",
      "train Loss: 0.1651\n",
      "val Loss: 0.0348\n",
      "\n",
      "Epoch 2/15\n",
      "------------------------------\n",
      "train Loss: 0.0608\n",
      "val Loss: 0.0254\n",
      "\n",
      "Epoch 3/15\n",
      "------------------------------\n",
      "train Loss: 0.0440\n",
      "val Loss: 0.0295\n",
      "\n",
      "Epoch 4/15\n",
      "------------------------------\n",
      "train Loss: 0.0502\n",
      "val Loss: 0.0190\n",
      "\n",
      "Epoch 5/15\n",
      "------------------------------\n",
      "train Loss: 0.0420\n",
      "val Loss: 0.0220\n",
      "\n",
      "Epoch 6/15\n",
      "------------------------------\n",
      "train Loss: 0.0242\n",
      "val Loss: 0.0116\n",
      "\n",
      "Epoch 7/15\n",
      "------------------------------\n",
      "train Loss: 0.0293\n",
      "val Loss: 0.0124\n",
      "\n",
      "Epoch 8/15\n",
      "------------------------------\n",
      "train Loss: 0.0260\n",
      "val Loss: 0.0100\n",
      "\n",
      "Epoch 9/15\n",
      "------------------------------\n",
      "train Loss: 0.0284\n",
      "val Loss: 0.0238\n",
      "\n",
      "Epoch 10/15\n",
      "------------------------------\n",
      "train Loss: 0.0188\n",
      "val Loss: 0.0075\n",
      "\n",
      "Epoch 11/15\n",
      "------------------------------\n",
      "train Loss: 0.0218\n",
      "val Loss: 0.0091\n",
      "\n",
      "Epoch 12/15\n",
      "------------------------------\n",
      "train Loss: 0.0156\n",
      "val Loss: 0.0100\n",
      "\n",
      "Epoch 13/15\n",
      "------------------------------\n",
      "train Loss: 0.0141\n",
      "val Loss: 0.0099\n",
      "\n",
      "Epoch 14/15\n",
      "------------------------------\n",
      "train Loss: 0.0199\n",
      "val Loss: 0.0055\n",
      "\n",
      "Epoch 15/15\n",
      "------------------------------\n",
      "train Loss: 0.0231\n",
      "val Loss: 0.0083\n",
      "\n",
      "Training complete in 19m 52s\n",
      "Best val Loss: 0.0055\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define Loss Function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define Optimizer (training only the classifier layers)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Define Learning Rate Scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Set number of epochs\n",
    "num_epochs = 15\n",
    "\n",
    "# Now Train the Model\n",
    "model, train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f608e",
   "metadata": {},
   "source": [
    "### Step 7: Define Single Image Prediction Function\n",
    "\n",
    "This function enables prediction of Tuberculosis (TB) status for a single uploaded chest X-ray image:\n",
    "\n",
    "- **Input Parameters**:\n",
    "  - `model`: The trained PyTorch model.\n",
    "  - `image_path`: Path to the input image (.jpg or .dcm).\n",
    "  - `transform`: The preprocessing transformations applied during training.\n",
    "  - `device`: The device (CPU or GPU) where the model is loaded.\n",
    "\n",
    "- **Image Loading**:\n",
    "  - If the image is `.jpg`, it is loaded and converted to RGB.\n",
    "  - If the image is `.dcm` (DICOM format), it is read using `pydicom`, normalized, converted to 8-bit RGB format.\n",
    "\n",
    "- **Preprocessing**:\n",
    "  - The loaded image undergoes resizing, normalization, and conversion to a tensor, similar to the training phase.\n",
    "\n",
    "- **Prediction**:\n",
    "  - The model outputs a probability score.\n",
    "  - A threshold of 0.5 is applied to determine whether the image is predicted as **TB Positive** or **TB Negative**.\n",
    "\n",
    "- **Output**:\n",
    "  - Returns the predicted label and the probability associated with the prediction.\n",
    "\n",
    "This function enables real-world testing where users can upload X-ray images and get instant TB detection results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21e57d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tb_from_image(model, image_path, transform, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Load image\n",
    "    if image_path.endswith('.jpg'):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    elif image_path.endswith('.dcm'):\n",
    "        dicom = pydicom.dcmread(image_path)\n",
    "        img_array = dicom.pixel_array\n",
    "\n",
    "        # Normalize and convert\n",
    "        img_array = img_array.astype(np.float32)\n",
    "        img_array = (img_array - np.min(img_array)) / (np.max(img_array) - np.min(img_array))\n",
    "        img_array = (img_array * 255).astype(np.uint8)\n",
    "        img_array = np.stack((img_array,)*3, axis=-1)\n",
    "        image = Image.fromarray(img_array)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {image_path}\")\n",
    "\n",
    "    # Apply same transform\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probability = output.item()\n",
    "        prediction = 1 if probability >= 0.5 else 0\n",
    "\n",
    "    label = \"TB Positive\" if prediction == 1 else \"TB Negative\"\n",
    "\n",
    "    return label, probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef6f61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    probs = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs_batch = outputs.squeeze().cpu().numpy()\n",
    "            preds_batch = (probs_batch >= 0.5).astype(int)\n",
    "\n",
    "            preds.extend(preds_batch)\n",
    "            probs.extend(probs_batch)\n",
    "            labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    probs = np.array(probs)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return preds, probs, labels\n",
    "\n",
    "# Now evaluate\n",
    "preds, probs, true_labels = evaluate_model(model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e462604",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate Model on Validation Set\n",
    "\n",
    "This step defines the evaluation procedure for assessing model performance on the validation dataset:\n",
    "\n",
    "- **Function `evaluate_model`**:\n",
    "  - The model is set to evaluation mode using `model.eval()`.\n",
    "  - Predictions (`preds`), predicted probabilities (`probs`), and true labels (`labels`) are collected across the validation set without updating model weights (`torch.no_grad()`).\n",
    "\n",
    "- **Processing**:\n",
    "  - Inputs are passed through the model.\n",
    "  - Outputs (probabilities) are thresholded at 0.5 to obtain binary class predictions (0 = TB Negative, 1 = TB Positive).\n",
    "  - All predictions, probabilities, and ground truths are gathered into NumPy arrays for further evaluation.\n",
    "\n",
    "- **Return Values**:\n",
    "  - `preds`: Final predicted labels (0 or 1).\n",
    "  - `probs`: Probability scores between 0 and 1.\n",
    "  - `labels`: Actual ground truth labels.\n",
    "\n",
    "This function enables calculation of key performance metrics such as Accuracy, Precision, Recall, F1-Score, Confusion Matrix, and ROC Curve for validating model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d73944e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7196\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " TB Negative       0.99      1.00      1.00       101\n",
      " TB Positive       1.00      1.00      1.00       501\n",
      "\n",
      "    accuracy                           1.00       602\n",
      "   macro avg       1.00      1.00      1.00       602\n",
      "weighted avg       1.00      1.00      1.00       602\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Accuracy\n",
    "accuracy = np.mean(preds == true_labels)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 2. Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, preds, target_names=[\"TB Negative\", \"TB Positive\"]))\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"TB Negative\", \"TB Positive\"], yticklabels=[\"TB Negative\", \"TB Positive\"])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4. ROC Curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, probs)\n",
    "auc = roc_auc_score(true_labels, probs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279006bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'tb_detection_model.pth')\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb58cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model.load_state_dict(torch.load('tb_detection_model.pth'))\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e7f75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model dynamically based on name\n",
    "def create_model(model_name):\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    elif model_name == \"resnet34\":\n",
    "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "    elif model_name == \"densenet121\":\n",
    "        model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "    # Freeze early layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Modify final classifier layers\n",
    "    if \"resnet\" in model_name:\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    elif \"densenet\" in model_name:\n",
    "        num_features = model.classifier.in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12f6ff0",
   "metadata": {},
   "source": [
    "### Step 9: Multi-Model Benchmarking and Best Model Selection\n",
    "\n",
    "To improve model performance and robustness, multiple deep learning architectures were evaluated:\n",
    "\n",
    "- **Models Benchmarked**:\n",
    "  - ResNet18\n",
    "  - ResNet34\n",
    "  - DenseNet121\n",
    "\n",
    "- **Benchmarking Strategy**:\n",
    "  - Transfer Learning: Early layers frozen, custom classifier head added.\n",
    "  - Same training and evaluation pipeline used for all models.\n",
    "  - Each model trained for 10 epochs for rapid comparison.\n",
    "  - Evaluated using Validation Accuracy and AUC (Area Under the ROC Curve).\n",
    "\n",
    "- **Results**:\n",
    "\n",
    "| Model        | Accuracy | AUC    |\n",
    "|--------------|----------|--------|\n",
    "| ResNet18     | 50.6%    | 0.9192 |\n",
    "| ResNet34     | 50.3%    | 0.8615 |\n",
    "| DenseNet121  | 49.6%    | 0.8449 |\n",
    "\n",
    "- **Best Model Selected**:\n",
    "  - Based on highest AUC score, **ResNet18** was selected as the best model for final deployment.\n",
    "  - AUC of ResNet18: **0.9192**, indicating strong ability to distinguish between TB Positive and TB Negative cases.\n",
    "\n",
    "This benchmarking step ensures the most suitable architecture was selected for final evaluation and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c485dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 Training model: resnet18\n",
      "Epoch 1/10\n",
      "------------------------------\n",
      "train Loss: 0.1244\n",
      "val Loss: 0.0252\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n",
      "train Loss: 0.0612\n",
      "val Loss: 0.0281\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n",
      "train Loss: 0.0419\n",
      "val Loss: 0.0169\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n",
      "train Loss: 0.0423\n",
      "val Loss: 0.0104\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n",
      "train Loss: 0.0287\n",
      "val Loss: 0.0112\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n",
      "train Loss: 0.0205\n",
      "val Loss: 0.0125\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n",
      "train Loss: 0.0194\n",
      "val Loss: 0.0225\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n",
      "train Loss: 0.0217\n",
      "val Loss: 0.0197\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n",
      "train Loss: 0.0141\n",
      "val Loss: 0.0091\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n",
      "train Loss: 0.0153\n",
      "val Loss: 0.0097\n",
      "\n",
      "Training complete in 12m 38s\n",
      "Best val Loss: 0.0091\n",
      "\n",
      "🔵 Training model: resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3.6%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\aryas/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "------------------------------\n",
      "train Loss: 0.1668\n",
      "val Loss: 0.0438\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n",
      "train Loss: 0.0676\n",
      "val Loss: 0.0272\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n",
      "train Loss: 0.0722\n",
      "val Loss: 0.0307\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n",
      "train Loss: 0.0915\n",
      "val Loss: 0.0345\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n",
      "train Loss: 0.0431\n",
      "val Loss: 0.0189\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n",
      "train Loss: 0.0319\n",
      "val Loss: 0.0134\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n",
      "train Loss: 0.0391\n",
      "val Loss: 0.0146\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n",
      "train Loss: 0.0199\n",
      "val Loss: 0.0127\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n",
      "train Loss: 0.0233\n",
      "val Loss: 0.0154\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n",
      "train Loss: 0.0201\n",
      "val Loss: 0.0146\n",
      "\n",
      "Training complete in 20m 60s\n",
      "Best val Loss: 0.0127\n",
      "\n",
      "🔵 Training model: densenet121\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\aryas/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "------------------------------\n",
      "train Loss: 0.2243\n",
      "val Loss: 0.0765\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n",
      "train Loss: 0.0895\n",
      "val Loss: 0.0460\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n",
      "train Loss: 0.0713\n",
      "val Loss: 0.0462\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n",
      "train Loss: 0.0533\n",
      "val Loss: 0.0174\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n",
      "train Loss: 0.0457\n",
      "val Loss: 0.0222\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n",
      "train Loss: 0.0451\n",
      "val Loss: 0.0287\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n",
      "train Loss: 0.0346\n",
      "val Loss: 0.0140\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n",
      "train Loss: 0.0388\n",
      "val Loss: 0.0192\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n",
      "train Loss: 0.0305\n",
      "val Loss: 0.0124\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n",
      "train Loss: 0.0309\n",
      "val Loss: 0.0125\n",
      "\n",
      "Training complete in 27m 56s\n",
      "Best val Loss: 0.0124\n",
      "\n",
      "📊 Model Comparison Results:\n",
      "         Model  Accuracy     AUC\n",
      "0     resnet18    0.7185  1.0000\n",
      "1     resnet34    0.7207  0.9999\n",
      "2  densenet121    0.7219  1.0000\n",
      "\n",
      "✅ Best Model based on AUC: resnet18\n"
     ]
    }
   ],
   "source": [
    "# List of models to benchmark\n",
    "model_names = [\"resnet18\", \"resnet34\", \"densenet121\"]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for name in model_names:\n",
    "    print(f\"\\n🔵 Training model: {name}\")\n",
    "    model = create_model(name)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    model, train_losses, val_losses = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=10  # Train quickly (short benchmarking)\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    preds, probs, true_labels = evaluate_model(model, val_loader, device)\n",
    "\n",
    "    accuracy = np.mean(preds == true_labels)\n",
    "    auc = roc_auc_score(true_labels, probs)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': round(accuracy, 4),\n",
    "        'AUC': round(auc, 4)\n",
    "    })\n",
    "\n",
    "# Display comparison\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n📊 Model Comparison Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Pick the best model\n",
    "best_model_name = results_df.sort_values(by=\"AUC\", ascending=False).iloc[0][\"Model\"]\n",
    "print(f\"\\n✅ Best Model based on AUC: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88bbcb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model weights\n",
    "torch.save(model.state_dict(), 'best_tb_detection_model.pth')\n",
    "\n",
    "\n",
    "print(\"Model weights saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ca4d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "------------------------------\n",
      "train Loss: 0.1401\n",
      "val Loss: 0.0496\n",
      "\n",
      "Epoch 2/20\n",
      "------------------------------\n",
      "train Loss: 0.0590\n",
      "val Loss: 0.0217\n",
      "\n",
      "Epoch 3/20\n",
      "------------------------------\n",
      "train Loss: 0.0456\n",
      "val Loss: 0.0111\n",
      "\n",
      "Epoch 4/20\n",
      "------------------------------\n",
      "train Loss: 0.0435\n",
      "val Loss: 0.0099\n",
      "\n",
      "Epoch 5/20\n",
      "------------------------------\n",
      "train Loss: 0.0306\n",
      "val Loss: 0.0080\n",
      "\n",
      "Epoch 6/20\n",
      "------------------------------\n",
      "train Loss: 0.0201\n",
      "val Loss: 0.0080\n",
      "\n",
      "Epoch 7/20\n",
      "------------------------------\n",
      "train Loss: 0.0146\n",
      "val Loss: 0.0105\n",
      "\n",
      "Epoch 8/20\n",
      "------------------------------\n",
      "train Loss: 0.0156\n",
      "val Loss: 0.0083\n",
      "\n",
      "Epoch 9/20\n",
      "------------------------------\n",
      "train Loss: 0.0134\n",
      "val Loss: 0.0119\n",
      "\n",
      "Epoch 10/20\n",
      "------------------------------\n",
      "train Loss: 0.0184\n",
      "val Loss: 0.0125\n",
      "\n",
      "Epoch 11/20\n",
      "------------------------------\n",
      "train Loss: 0.0166\n",
      "val Loss: 0.0095\n",
      "\n",
      "Epoch 12/20\n",
      "------------------------------\n",
      "train Loss: 0.0154\n",
      "val Loss: 0.0090\n",
      "\n",
      "Epoch 13/20\n",
      "------------------------------\n",
      "train Loss: 0.0100\n",
      "val Loss: 0.0085\n",
      "\n",
      "Epoch 14/20\n",
      "------------------------------\n",
      "train Loss: 0.0222\n",
      "val Loss: 0.0107\n",
      "\n",
      "Epoch 15/20\n",
      "------------------------------\n",
      "train Loss: 0.0165\n",
      "val Loss: 0.0081\n",
      "\n",
      "Epoch 16/20\n",
      "------------------------------\n",
      "train Loss: 0.0208\n",
      "val Loss: 0.0096\n",
      "\n",
      "Epoch 17/20\n",
      "------------------------------\n",
      "train Loss: 0.0142\n",
      "val Loss: 0.0077\n",
      "\n",
      "Epoch 18/20\n",
      "------------------------------\n",
      "train Loss: 0.0131\n",
      "val Loss: 0.0123\n",
      "\n",
      "Epoch 19/20\n",
      "------------------------------\n",
      "train Loss: 0.0154\n",
      "val Loss: 0.0086\n",
      "\n",
      "Epoch 20/20\n",
      "------------------------------\n",
      "train Loss: 0.0200\n",
      "val Loss: 0.0102\n",
      "\n",
      "Training complete in 30m 9s\n",
      "Best val Loss: 0.0077\n",
      "✅ Final model saved as 'best_tb_detection_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a fresh best model (ResNet18)\n",
    "best_model = create_model('resnet18')\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "# 2. Define loss, optimizer, scheduler\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, best_model.parameters()), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 3. Retrain the best model for 20 epochs\n",
    "num_epochs = 20\n",
    "best_model, train_losses, val_losses = train_model(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "# 4. Save the best model\n",
    "torch.save(best_model.state_dict(), 'best_tb_detection_model.pth')\n",
    "print(\"✅ Final model saved as 'best_tb_detection_model.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
